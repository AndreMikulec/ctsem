  %\VignetteIndexEntry{Introduction to Hierarchical Continuous Time Dynamic Modelling with ctsem} 
  %\VignetteKeyword{SEM, time series, panel data, dynamic models}
  %\VignetteEngine{knitr::knitr} 
\documentclass[nojss]{jss}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{amsmath} %for multiple line equations
 \usepackage[libertine]{newtxmath}

 \makeatletter
 \re@DeclareMathSymbol{\alpha}{\mathord}{lettersA}{11}
 \re@DeclareMathSymbol{\beta}{\mathord}{lettersA}{12}
 \re@DeclareMathSymbol{\gamma}{\mathord}{lettersA}{13}
 \re@DeclareMathSymbol{\delta}{\mathord}{lettersA}{14}
 \re@DeclareMathSymbol{\epsilon}{\mathord}{lettersA}{15}
 \re@DeclareMathSymbol{\zeta}{\mathord}{lettersA}{16}
 \re@DeclareMathSymbol{\eta}{\mathord}{lettersA}{17}
 \re@DeclareMathSymbol{\theta}{\mathord}{lettersA}{18}
 \re@DeclareMathSymbol{\iota}{\mathord}{lettersA}{19}
 \re@DeclareMathSymbol{\kappa}{\mathord}{lettersA}{20}
 \re@DeclareMathSymbol{\lambda}{\mathord}{lettersA}{21}
 \re@DeclareMathSymbol{\mu}{\mathord}{lettersA}{22}
 \re@DeclareMathSymbol{\nu}{\mathord}{lettersA}{23}
 \iftx@altnu
 \re@DeclareMathSymbol{\nu}{\mathord}{lettersA}{40}
 \fi
 \re@DeclareMathSymbol{\xi}{\mathord}{lettersA}{24}
 \re@DeclareMathSymbol{\pi}{\mathord}{lettersA}{25}
 \re@DeclareMathSymbol{\rho}{\mathord}{lettersA}{26}
 \re@DeclareMathSymbol{\sigma}{\mathord}{lettersA}{27}
 \re@DeclareMathSymbol{\tau}{\mathord}{lettersA}{28}
 \re@DeclareMathSymbol{\upsilon}{\mathord}{lettersA}{29}
 \re@DeclareMathSymbol{\phi}{\mathord}{lettersA}{30}
 \re@DeclareMathSymbol{\chi}{\mathord}{lettersA}{31}
 \re@DeclareMathSymbol{\psi}{\mathord}{lettersA}{32}
 \re@DeclareMathSymbol{\omega}{\mathord}{lettersA}{33}
 \re@DeclareMathSymbol{\varepsilon}{\mathord}{lettersA}{34}
 \re@DeclareMathSymbol{\vartheta}{\mathord}{lettersA}{35}
 \re@DeclareMathSymbol{\varpi}{\mathord}{lettersA}{36}
 \re@DeclareMathSymbol{\varrho}{\mathord}{lettersA}{37}
 \re@DeclareMathSymbol{\varsigma}{\mathord}{lettersA}{38}
 \re@DeclareMathSymbol{\varphi}{\mathord}{lettersA}{39}
 \makeatother

\usepackage{bm}
\newcommand{\vect}[1]{\boldsymbol{\mathbf{#1}}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% almost as usual
\author{Charles C. Driver \\ Max Planck Institute for Human Development \And 
Manuel C. Voelkle \\ Humboldt University Berlin \\ Max Planck Institute for Human Development}
\title{Introduction to Hierarchical Continuous Time Dynamic Modelling With \pkg{ctsem}}

%% for pretty printing and a nice hypersummary also set:
\Plainauthor{Charles C. Driver, Manuel C. Voelkle} %% comma-separated
\Plaintitle{Introduction to Hierarchical Continuous Time Dynamic Modelling with ctsem} %% without formatting
\Shorttitle{Introduction to Hierarchical Continuous Time Dynamic Modelling with \pkg{ctsem}} %% a short title (if necessary)

\Abstract{
ctsem allows for specification and fitting of a range of continuous and discrete time dynamic models with stochastic system noise. The models may include multiple indicators (dynamic factor analysis), multiple, interrelated, potentially higher order processes, and time dependent (varying within subject) and time independent (not varying within subject) covariates. Classic longitudinal models like latent growth curves and latent change score models are also possible.  Version 1 of ctsem provided structural equation model based functionality by linking to the OpenMx software, allowing mixed effects models (random means but fixed regression and variance parameters) for multiple subjects. For version 2 of the \proglang{R} package \pkg{ctsem}, we include a Bayesian specification and fitting routine that uses the \pkg{Stan} probabilistic programming language, via the \pkg{rstan} package in R. This allows for all parameters of the dynamic model to individually vary, using an estimated population mean and variance, and any time independent covariate effects, as a prior. Frequentist approaches with ctsem are documented in a JSS publication \citep{driver2017continuous}, and in R vignette form at \url{https://cran.r-project.org/package=ctsem/vignettes/ctsem.pdf }. The Bayesian approach is discussed more fully and conceptually in a preprint article \citep{driver2016hierarchical}available at \url{https://www.researchgate.net/publication/310747801_Hierarchical_Bayesian_Continuous_Time_Dynamic_Modeling}, but here we provide more specifics on the software for getting started with the software of the Bayesian approach.
}

\Keywords{hierarchical time series, Bayesian, longitudinal, panel data, state space, structural equation, continuous time, stochastic differential equation, dynamic models, Kalman filter, \proglang{R}}
\Plainkeywords{hierarchical time series, longitudinal, panel data, state space, structural equation, continuous time, stochastic differential equation, dynamic models, Kalman filter, R} %% without formatting
%% at least one keyword must be supplied

%% publication information
%% NOTE: Typically, this can be left commented and will be filled out by the technical editor
%% \Volume{50}
%% \Issue{9}
%% \Month{June}
%% \Year{2012}
%% \Submitdate{2012-06-04}
%% \Acceptdate{2012-06-04}

%% The address of (at least) one author should be given
%% in the following format:
\Address{
Charles Driver\\
Center for Lifespan Psychology\\
Max Planck Institute for Human Development\\
Lentzeallee 94, 14195 Berlin\\
Telephone: +49 30 82406-367
E-mail: \email{driver@mpib-berlin.mpg.de}\\
URL: \url{http://www.mpib-berlin.mpg.de/en/staff/charles-driver}
}
%% It is also possible to add a telephone and fax number
%% before the e-mail in the following format:
%% Telephone: +43/512/507-7103
%% Fax: +43/512/507-2851

%% for those who use Sweave please include the following line (with % symbols):
%% need no \usepackage{Sweave.sty}

%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\usepackage{amsmath} %for multiple line equations
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}} %for adding numbers to specific lines

% Set lowercase greek letters to non-italicised
% \usepackage{Sweavel}
% \usepackage{Sweave}
\usepackage[libertine]{newtxmath}
\usepackage[pdftex]{thumbpdf}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}



\section{Overview}


\subsection{Subject Level Latent Dynamic model}
This section describes the fundamental subject level model, and where appropriate, the name of the ctModel argument used to specify specific matrices. The description of the full model, including subject level likelihood and population model, is provided in \citet{driver2016hierarchical}, available at \url{https://www.researchgate.net/publication/310747801_Hierarchical_Bayesian_Continuous_Time_Dynamic_Modeling}. Although we do not describe it explicitly, the corresponding discrete time autoregressive / moving average models can be specified and use the same set of parameter matrices we describe, although the meaning is of course somewhat different.

\subsection{Subject level latent dynamic model}
The subject level dynamics are described by the following stochastic differential equation:
\begin{equation}
\label{eq:process1}
\mathrm{d} \vect{\eta} (t) =
\bigg( 
\vect{A \eta} (t) +
\vect{b} +
\vect{M \chi} (t)  
\bigg) \mathrm{d} t +
\vect{G} \mathrm{d} \vect{W}(t)  
\end{equation}

Vector $ \vect{\eta} (t)\in\mathbb{R}^{v}$ represents the state of the latent processes at time $t$. The matrix $ \vect{A} \in \mathbb{R}^{v \times v}$ (DRIFT) represents the so-called drift matrix, with auto effects on the diagonal and cross effects on the off-diagonals characterizing the temporal dynamics of the processes. 

The continuous time intercept vector $ \vect{b} \in\mathbb{R}^{v}$ (CINT), in combination with $\vect{A}$, determines the long-term level at which the processes fluctuate around.

Time dependent predictors $\vect{\chi}(t)$ represent inputs to the system that vary over time and are independent of fluctuations in the system. Equation \ref{eq:process1} shows a generalized form for time dependent predictors, that could be treated a variety of ways dependent on the assumed time course (or shape) of time dependent predictors. We use a simple impulse form shown in Equation \ref{eq:spike}, in which the predictors are treated as impacting the processes only at the instant of an observation occasion $u$. When necessary, the evolution over time can be modeled by extending the state matrices, for examples and discussion see \citet{driver2017understanding}.

\begin{equation}
\label{eq:spike}
\vect{\chi} (t) = \sum_{ u \in \vect{U}}  \vect{x}_{u} \delta (t-t_u)     
\end{equation}

Here, time dependent predictors $\vect{x}_u \in \mathbb{R}^{l}$ (tdpreds) are observed at measurement occasions $ u \in \vect{U}$. The Dirac delta function $\delta(t-t_u)$ is a generalized function that is $\infty$ at 0 and 0 elsewhere, yet has an integral of 1 (when 0 is in the range of integration). It is useful to model an impulse to a system, and here is scaled by the vector of time dependent predictors $\vect{x}_u$.  The effect of these impulses on processes $\vect{\eta}(t)$ is then $\vect{M}\in \mathbb{R}^{v \times l}$ (TDPREDEFFECT). 

$\vect{W}(t) \in \mathbb{R}^{v}$ (DIFFUSION) represents independent Wiener processes, with a Wiener process being a random-walk in continuous time. $\textnormal{d}\vect{W}(t)$ is meaningful in the context of stochastic differential equations, and represents the stochastic error term, an infinitesimally small increment of the Wiener process. Lower triangular matrix $\vect{G} \in \mathbb{R}^{v \times v}$ represents the effect of this noise on the change in  $\vect{\eta}(t)$.  $\vect{Q}$, where $\vect{Q} = \vect{GG}^\top$, represents the variance-covariance matrix of the diffusion process in continuous time.

\subsection{Subject level measurement model}
The latent process vector $\vect{\eta}(t)$ has measurement model:

\begin{equation}
	\label{eq:measurement}
	\vect{y}(t) = \vect{\Lambda} \vect{\eta}(t) + \vect{\tau} + \vect{\epsilon}(t)  
	\quad \text{where } \vect{\epsilon}(t) \sim  \mathrm{N} (\vect{0}_c, \vect{\Theta})
\end{equation}

$\vect{y} (t)\in\mathbb{R}^{c}$ is the vector of manifest variables, $\vect{\Lambda} \in \mathbb{R}^{c \times v}$ (LAMBDA) represents the factor loadings, and $\vect{\tau} \in\mathbb{R}^{c}$ (MANIFESTMEANS) the manifest intercepts. The residual vector $\vect{\epsilon} \in \mathbb{R}^{c}$ has covariance matrix $\vect{\Theta} \in\mathbb{R}^{c \times c}$ (MANIFESTVAR).

\subsection{Overview of hierarchical model}
Parameters for each subject are first drawn from a simultaneously estimated higher level distribution over an unconstrained space, then a set of parameter specific transformations are applied so that a) each parameter conforms to necessary bounds and b) is subject to the desired prior, then a range of matrix transformations are applied to generate the continuous time matrices described, as well as all relevant discrete time instantiations (More variability in measurement time intervals thus means more computations). The higher level distribution has a multivariate normal prior. A more comprehensive description is found at the end of this document. 

\subsection{Install software and prepare data}
Install ctsem software:

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{install.packages}\hlstd{(}\hlstr{"ctsem"}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

Prepare data in long format, each row containing one time point of data for one subject. We need a subject id column containing numbers from 1 to total subjects, rising incrementally with each subject going down the data structure. This is to ensure coherence with the internal structure of the Stan model. The column is named by default "id", though this can be changed in the model specification. We also need a time column "time", containing numeric values for time, columns for manifest variables (the names of which must be given in the next step using ctModel), columns for time dependent predictors (these vary over time but have no model estimated and are assumed to impact latent processes instantly), and columns for time independent predictors (which predict the subject level parameters, that are themselves time invariant -- thus the values for a particular time independent predictor must be the same across all observations of a particular subject).

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{verbatim}
     id  time     Y1    Y2     TD1      TI1    TI2     TI3
[1,]  1 -0.05 -0.776  5.26  1.6153 -1.08039 -1.607  0.0324
[2,]  1  1.25 -0.310  4.91  0.4244 -1.08039 -1.607  0.0324
[3,]  1  2.10 -1.167  5.14  0.6623 -1.08039 -1.607  0.0324
[4,]  1  3.03  0.336  5.16  0.0561 -1.08039 -1.607  0.0324
[5,]  1  3.98 -0.134  4.97  2.3243 -1.08039 -1.607  0.0324
[6,]  2 36.06 -5.006 -5.79  0.9433 -0.00619  0.643 -0.5037
[7,]  2 36.88 -6.287 -4.41 -0.0220 -0.00619  0.643 -0.5037
[8,]  2 37.87 -7.257 -4.00 -0.4195 -0.00619  0.643 -0.5037
\end{verbatim}
\end{kframe}
\end{knitrout}

At present, missingness is fine on manifest indicators, but not allowed elsewhere.

\subsection{Model specification}
Specify model using \code{ctModel(type="stanct",...)}. "stanct" specifies a continuous time model in Stan format, "standt" specifies discrete time, while "omx" is the classic \pkg{ctsem} behaviour and prepares an \pkg{OpenMx} model. Other arguments to ctModel proceed as normal, although some matrices used for type `omx' are not relevant for the Stan formats, either because the between subject matrices have been removed, or because time dependent and independent predictors are now treated as fixed regressors and only require effect (or design) matrices. These differences are documented in the help for ctModel.

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{model}\hlkwb{<-}\hlkwd{ctModel}\hlstd{(}\hlkwc{type}\hlstd{=}\hlstr{'stanct'}\hlstd{,}
  \hlkwc{n.latent}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{latentNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'eta1'}\hlstd{,}\hlstr{'eta2'}\hlstd{),}
  \hlkwc{n.manifest}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{manifestNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'Y1'}\hlstd{,}\hlstr{'Y2'}\hlstd{),}
  \hlkwc{n.TDpred}\hlstd{=}\hlnum{1}\hlstd{,} \hlkwc{TDpredNames}\hlstd{=}\hlstr{'TD1'}\hlstd{,}
  \hlkwc{n.TIpred}\hlstd{=}\hlnum{3}\hlstd{,} \hlkwc{TIpredNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'TI1'}\hlstd{,}\hlstr{'TI2'}\hlstd{,}\hlstr{'TI3'}\hlstd{),}
  \hlkwc{LAMBDA}\hlstd{=}\hlkwd{diag}\hlstd{(}\hlnum{2}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

This generates a first order bivariate latent process model, with each process measured by a single, potentially noisy, manifest variable. A single time dependent predictor is included in the model, and three time independent predictors. Additional complexity or restrictions may be added, the table below shows the basic arguments one may consider and their link to the dynamic model parameters. For more details see the ctsem help files or papers. Note that for the Stan implementation, ctModel requires variance covariance matrices (DIFFUSION, T0VAR, MANIFESTVAR) to be specified with standard deviations on the diagonal, correlations (partial, if > 2 latent processes) the lower off diagonal, and zeroes on the upper off diagonal. 

\begin{table}\footnotesize
\begin{tabular}{l|l|l p{8cm} }
\textbf{Argument} & \textbf{Sign} & \textbf{Default} & \textbf{Meaning}\\
\hline
 n.manifest & \textit{c} & & Number of manifest indicators per individual at each measurement occasion.\\
 n.latent & \textit{v} & & Number of latent processes.\\
 LAMBDA & $\Lambda$& & n.manifest $\times$ n.latent loading matrix relating latent to manifest variables.\\
 manifestNames & & Y1, Y2, etc & n.manifest length character vector of manifest names.\\
 latentNames & & eta1, eta2, etc & n.latent length character vector of latent names.\\
 T0VAR & $Q^*_1$ & free & lower tri n.latent $\times$ n.latent matrix of latent process initial covariance, specified with standard deviations on diagonal and (partial) correlations on lower triangle.\\
 T0MEANS & $\eta_1$ & free & n.latent $\times$ 1 matrix of latent process means at first time point, T0.\\
 MANIFESTMEANS & $\tau$ & free & n.manifest $\times$ 1 matrix of manifest means.\\
 MANIFESTVAR & $\Theta$ & free diag & lower triangular matrix of var / cov between manifests, specified with standard deviations on diagonal and (partial) correlations on lower triangle.\\
 DRIFT & $A$ & free & n.latent $\times$ n.latent matrix of continuous auto and cross effects.\\
 CINT & $b$ & 0 & n.latent $\times$ 1 matrix of continuous intercepts.\\
 DIFFUSION & $Q$ & free & lower triangular n.latent $\times$ n.latent matrix containing standard deviations of latent process on diagonal, and (partial) correlations on lower off-diagonals.\\
 n.TDpred & \textit{l} & 0 & Number of time dependent predictors in the dataset.\\
 TDpredNames & & TD1, TD2, etc & n.TDpred length character vector of time dependent predictor names.\\
 TDPREDEFFECT & $M$ & free & n.latent $\times$ n.TDpred matrix of effects from time dependent predictors to latent processes.\\
 n.TIpred & \textit{p} & 0 & Number of time independent predictors.\\
 TIpredNames & & TI1, TI2, etc & n.TIpred length character vector of time independent predictor names.\\
\end{tabular}
\end{table}

These matrices may all be specified using a combination of character strings to name free parameters, or numeric values to represent fixed parameters. 

The parameters subobject of the created model object shows the parameter specification that will go into Stan, including both fixed and free parameters, whether the parameters vary across individuals, how the parameter is transformed from a standard normal distribution (thus setting both priors and bounds), and whether that parameter is regressed on the time independent predictors.

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{head}\hlstd{(model}\hlopt{$}\hlstd{pars,}\hlnum{8}\hlstd{)}
\end{alltt}
\begin{verbatim}
   matrix row col           param value                      transform indvarying sdscale
1 T0MEANS   1   1     T0mean_eta1    NA                   (param) * 10       TRUE       1
2 T0MEANS   2   1     T0mean_eta2    NA                   (param) * 10       TRUE       1
3  LAMBDA   1   1            <NA>     1                           <NA>      FALSE       1
4  LAMBDA   1   2            <NA>     0                           <NA>      FALSE       1
5  LAMBDA   2   1            <NA>     0                           <NA>      FALSE       1
6  LAMBDA   2   2            <NA>     1                           <NA>      FALSE       1
7   DRIFT   1   1 drift_eta1_eta1    NA -log(exp(-param*1.5)+1)-.00001       TRUE       1
8   DRIFT   1   2 drift_eta1_eta2    NA                        (param)       TRUE       1
  TI1_effect TI2_effect TI3_effect
1       TRUE       TRUE       TRUE
2       TRUE       TRUE       TRUE
3      FALSE      FALSE      FALSE
4      FALSE      FALSE      FALSE
5      FALSE      FALSE      FALSE
6      FALSE      FALSE      FALSE
7       TRUE       TRUE       TRUE
8       TRUE       TRUE       TRUE
\end{verbatim}
\end{kframe}
\end{knitrout}

One may modify the output model to either restrict between subject differences (set some parameters to not vary over individuals), alter the transformation used to determine the prior / bounds, or restrict which effects of time independent predictors to estimate. Plotting the original prior, making a change, and plotting the resulting prior, are shown here -- in this case we believe the stochastic latent process innovation for our first latent process, captured by row 1 and column 1 of the DIFFUSION matrix, to be small, so scale our prior accordingly to both speed and improve sampling. Rather than simply scaling by 0.2 as shown here, one could also construct a new form of prior, so long as the resulting distribution was within the bounds required for the specific parameter. Note that the resulting distribution is a result of applying the specified transformation to a standard normal distribution, with mean of 0 and standard deviation of 1. To change the underlying standard normal, one would need to edit the resulting Stan code directly.

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{par}\hlstd{(}\hlkwc{mfrow}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{1}\hlstd{,}\hlnum{2}\hlstd{))}
\hlkwd{plot}\hlstd{(model,}\hlkwc{rows}\hlstd{=}\hlnum{11}\hlstd{,}\hlkwc{hypersd}\hlstd{=}\hlnum{1}\hlstd{)}
\hlkwd{print}\hlstd{(model}\hlopt{$}\hlstd{pars}\hlopt{$}\hlstd{transform[}\hlnum{11}\hlstd{])}
\end{alltt}
\begin{verbatim}
[1] "exp(param*2)"
\end{verbatim}
\begin{alltt}
\hlstd{model}\hlopt{$}\hlstd{pars}\hlopt{$}\hlstd{transform[}\hlnum{11}\hlstd{]}\hlkwb{<-} \hlstr{"(exp(param*2) +.0001)*.2"}
\hlkwd{plot}\hlstd{(model,} \hlkwc{rows}\hlstd{=}\hlnum{11}\hlstd{,} \hlkwc{hypersd}\hlstd{=}\hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/transform-1} 

}



\end{knitrout}

The plots show the prior distribution for the population mean of DIFFUSION[1,1] in black, as well as two possible priors for the subject level parameters, conditional on our specified population (hyper) standard deviation of 1. The blue prior results from assuming the population mean is one standard deviation lower than the mean of the prior, and the red one standard deviation higher. This latter prior can be scaled using the sdscale column of the parameters subobject.

Restrict between subject effects as desired. Unnecessary between subject effects will slow sampling and hinder appropriate regularization, but be aware of the many parameter dependencies in these models -- restricting one parameter may lead to genuine variation in the restricted parameter expressing itself elsewhere. The prior scale for between subject variance may need to be restricted when limited data (in either the number of time points or number of subjects) is available, to ensure adequate regularisation. Here we restrict MANIFESTVAR effects between subjects, and set all prior scales for the standard deviation of the population distribution to 0.2, from the default of 1.0. A rough interpretation of this change in sdscale is simply that we expect lower values for the population standard deviation, but to better interpret the effect of this latter change, see the section on standard deviation transformations.

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{model}\hlopt{$}\hlstd{pars[}\hlkwd{c}\hlstd{(}\hlnum{15}\hlstd{,}\hlnum{18}\hlstd{),]}\hlopt{$}\hlstd{indvarying}\hlkwb{<-}\hlnum{FALSE}
\hlstd{model}\hlopt{$}\hlstd{pars}\hlopt{$}\hlstd{sdscale[}\hlnum{1}\hlopt{:}\hlnum{28}\hlstd{]} \hlkwb{<-} \hlnum{.5}
\end{alltt}
\end{kframe}
\end{knitrout}

Also restrict which parameters to include time independent predictor effects for in a similar way, for similar reasons. In this case, the only adverse effects of restriction are that the relationship between the predictor and variables will not be estimated, but the subject level parameters themselves should not be very different, as they are still freely estimated. Note that such effects are only estimated for individually varying parameters anyway -- so after the above change there is no need to set the tipredeffect to FALSE for the T0VAR variables, it is assumed. Instead, we restrict the tipredeffects on all parameters, and free them only for the manifest intercept parameters.

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{model}\hlopt{$}\hlstd{pars[,}\hlkwd{c}\hlstd{(}\hlstr{'TI1_effect'}\hlstd{,}\hlstr{'TI2_effect'}\hlstd{,}\hlstr{'TI3_effect'}\hlstd{)]}\hlkwb{<-}\hlnum{FALSE}
\hlstd{model}\hlopt{$}\hlstd{pars[}\hlkwd{c}\hlstd{(}\hlnum{19}\hlstd{,}\hlnum{20}\hlstd{),}\hlkwd{c}\hlstd{(}\hlstr{'TI1_effect'}\hlstd{,}\hlstr{'TI2_effect'}\hlstd{,}\hlstr{'TI3_effect'}\hlstd{)]}\hlkwb{<-}\hlnum{TRUE}
\end{alltt}
\end{kframe}
\end{knitrout}

\subsection{Model fitting}
Once model specification is complete, the model is fit to the data using the ctStanFit function as follows -- depending on the data, model, and number of iterations requested, this can take anywhere from a few minutes to days. Current experience suggests 300 iterations is often enough to get an idea of what is going on, but more may be necessary for robust inference. This will of course vary massively depending on model and data. For the sake of speed for this example we only sample for 200 iterations with a lowered max\_treedepth - this latter parameter controls the maximum number of steps the Hamiltonian sampler is allowed to take per iteration, with each increase of 1 doubling the maximum. With these settings the fit should take only a few minutes (but will not be adequate for inference!). Those that wish to try out the functions without waiting, can simply use the already existing ctstantestfit object instead of creating the fit object (and adjust the code in following sections as needed!).

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlstd{fit}\hlkwb{<-}\hlkwd{ctStanFit}\hlstd{(}\hlkwc{datalong} \hlstd{= ctstantestdat,} \hlkwc{ctstanmodel} \hlstd{= model,} \hlkwc{iter}\hlstd{=}\hlnum{200}\hlstd{,}
  \hlkwc{chains}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{plot}\hlstd{=}\hlnum{FALSE}\hlstd{,} \hlkwc{control}\hlstd{=}\hlkwd{list}\hlstd{(}\hlkwc{max_treedepth} \hlstd{=} \hlnum{6}\hlstd{))}
\end{alltt}
\end{kframe}
\end{knitrout}

The plot argument allows for plotting of sampling chains in real time, which is useful for slow models to ensure that sampling is proceeding in a functional manner. Models with many parameters (e.g., many subjects and all parameters varying over subject) may be too taxing for the function to handle smoothly - we have had succcess with up to around 4000 parameters.  

\subsection{Summary}
After fitting, the summary function may be used on the fit object, which returns details regarding the population mean parameters, population standard deviation parameters, population correlations, and the effect parameters of time independent predictors. 
Additionally, summary outputs a range of matrices regarding correlations betweeen subject level parameters. hypercorr\_means reports the posterior mean of the correlation between raw (not yet transformed from the standard normal scale) parameters. hypercorr\_sd reports the standard deviation of these parameters. hypercovcor\_transformedmean reports the correlation between transformed parameters on the lower triangle, the variance of these parameters on the diagonal, and the covariance on the upper triangle.
To view the posterior median of the continuous time parameter matrices, the ctStanContinuousPars function can be used.

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{summary}\hlstd{(fit,}\hlkwc{timeinterval} \hlstd{=} \hlnum{1}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

In the summary output, the free population mean parameters under \$popmeans are likely one of the main points of interest. They are returned in the same form that they are input to ctModel - that is, covariance matrix related parameters are in the form of either standard deviations or a transformed correlation parameter. Because the latter is difficult to interpret, various parameter matrices are also returned in the \$parmatrices section of the summary. The discrete time matrices reported here (prefixed by `dt') are by default from a time interval of 1, but this can be changed.

\subsection{Plotting}
The plot function outputs a sequence of plots, all generated by specific functions. The name of the specific function appears in a message in the R console, checking the help for each specific function and running them separately will allow more customization. Some of the plots, such as the trace, density, and interval, are generated by the relevant rstan function and hopefully self explanatory. The plots specific to the heirarchical continuous time dynamic model are as follows:

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}

{\centering \includegraphics[width=\maxwidth]{figure/plots1-1} 

}



\end{knitrout}

The above plot shows the dynamic regression coefficients (between latent states at different time points) that are implied by the model for particular time intervals, as well as the uncertainty of these coefficients.

The relation between posteriors and priors for variables of interest can also be plotted as follows:

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{ctStanPlotPost}\hlstd{(}\hlkwc{obj} \hlstd{= fit,} \hlkwc{rows}\hlstd{=}\hlnum{11}\hlstd{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/outputposterior-1} 

}



\end{knitrout}

Shown are approximate density plots based on the post-warmup samples drawn. For each parameter four plots are shown -- the first displays the posterior distribution of subject level parameters, the subject level prior (generated from repeated sampling of the hyper parameters), and the prior for the population mean.


\subsection{Stationarity}
When it is reasonable to assume that the prior for long term expectation and variance of the latent states is the same as (or very similar to) the prior for initial expectations and variances, setting some form of stationarity in advance may be beneficial. Three approaches to this are possible.
The first approach is to name free parameters of the T0VAR or T0MEANS matrix \verb{'stationary'{, which can be useful if for instance only the initial variance should be stationary, or just one of the initial variances. Another approach is to set the argument stationary=TRUE to ctStanFit. Specifying this argument then ignores any T0VAR and T0MEANS matrices in the input, instead replacing them with asymptotic expectations based on the DRIFT, DIFFUSION, and CINT matrices.
Alternatively, a prior can be placed on the stationarity of the dynamic models, calculated as the difference between the T0MEANS and the long run asymptotes of the expected value of the process, as well as the difference between the diagonals of the T0VAR covariance matrix and the long run asymptotes of the covariance of the processes. Such a prior encourages a minimisation of these differences, and can help to ensure that sensible, non-explosive models are estimated, and also help the sampler get past difficult regions of relative flatness in the parameter space due to colinearities between the within and between subject parameters. However if such a prior is too strong it can also induce difficult dependencies in model parameters, and there are a range of models where one may not wish to have such a prior. To place such a prior, the model\$stationarymeanprior and model\$stationaryvarprior slots can be changed from the default of NA to a numeric vector, representing the normal standard deviation of the deviations from stationarity. The number of elements in the vector correspond to the number of latent processes.

\subsection{Individual level analyses}
Individual level results can also be considered, as ctsem includes functionality to output prior (based on all prior observations), updated (based on all prior and current observations), and smoothed (based on all observations) expectations and covariances from the Kalman filter, based on specific subjects models. For ease of comparison, expected manifest indicator scores conditional on prior, updated and smoothed states are also included. This approach allows for: predictions regarding individuals states at any point in time, given any values on the time dependent predictors (external inputs such as interventions or events); residual analysis to check for unmodeled dependencies in the data; or simply as a means of visualization, for comprehension and model sanity checking purposes. An example of such is depicted below, where we see observed and estimated scores for a selected subject from our sample. If we wanted to predict unobserved states in the future, we would need only to specify the appropriate timerange (Prediction into earlier times is possible but makes little sense unless the model is restricted to stationarity).

\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{ctKalman}\hlstd{(fit,} \hlkwc{subjects}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{timerange}\hlstd{=}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{60}\hlstd{),} \hlkwc{kalmanvec}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'y'}\hlstd{,} \hlstr{'ysmooth'}\hlstd{),}
  \hlkwc{timestep}\hlstd{=}\hlnum{.1}\hlstd{,} \hlkwc{plot}\hlstd{=}\hlnum{TRUE}\hlstd{)}
\end{alltt}
\end{kframe}

{\centering \includegraphics[width=\maxwidth]{figure/kalmanplot-1} 

}



\end{knitrout}


\subsection{Accessing Stan model code}
For diagnosing problems or modifying the model in ways not achievable via the ctsem model specification, one can use ctsem to generate the Stan code and then work directly with that, simply by specifying the argument fit=FALSE to the ctStanFit function. Any altered code can be passed back into ctStanFit by using the stanmodeltext argument, which can be convenient for setting up the data in particular.

\subsection{Using Rstan functions}
The standard rstan output functions such as summary and extract are also available, and the shinystan package provides an excellent browser based interface. The stan fit object is stored under the \$stanfit subobject from the ctStanFit output. The parameters which are likely to be of most interest in the output are prefixed by "hmean\_" for hyper (population) mean, "hsd\_" for hyper standard deviation, and "tipred\_" for time independent predictor. Any hmean parameters are returned in the form used for input - so correlations and standard deviations for any of the covariance related parameters. Subject specific parameters are denoted by the matrix they are from, then the first index represents the subject id, followed by standard matrix notation. For example, the 2nd row and 1st column of the DRIFT matrix for subject 8 is $"DRIFT[8,2,1]"$. Parameters in such matrices are returned in the form used for internal calculations -- that is, variance covariance matrices are returned as such, rather than the lower-triangular standard deviation and correlation matrices required for input. The exception to this are the time independent predictor effects, prefixed with $"tipred\_"$, for which a linear effect of a change of 1 on the predictor is approximated. So although "tipred\_TI1" is only truly linear with respect to internal parameterisations, we approximate the linear effect by averaging the effect of a score of +1 or -1 on the predictor, on the population mean. For any subject that substantially differs from the mean, or simply when precise absolute values of the effects are required (as opposed to general directions), they will need to be calculated manually.


\subsection{Oscillating, single subject example - sunspots data}
In the following example we fit the sunspots data available within R, which has previously been fit by various authors including \citet{tomasson2013computational}. We have used the same CARMA(2,1) model and obtained similar estimates -- some differences are due to the contrast between Bayes and maximum likelihood, though if desired one could adjust the code to fit using maximum likelihood, as here we have only one subject. 
% There are usually some divergent transitions (indicating a difficulty in the sampling chain and a potential threat to inference) generated in this fit -- alternate parameterisations or an increase in the adapt\_delta control argument to Stan (which defaults to 0.9 in ctsem, with a maximum of 1, though 1 is not recommended...) may help.
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{#get data}
 \hlstd{sunspots}\hlkwb{<-}\hlstd{sunspot.year}
 \hlstd{sunspots}\hlkwb{<-}\hlstd{sunspots[}\hlnum{50}\hlopt{:} \hlstd{(}\hlkwd{length}\hlstd{(sunspots)} \hlopt{-} \hlstd{(}\hlnum{1988}\hlopt{-}\hlnum{1924}\hlstd{))]}
 \hlstd{id} \hlkwb{<-} \hlnum{1}
 \hlstd{time} \hlkwb{<-} \hlnum{1749}\hlopt{:}\hlnum{1924}
\hlstd{datalong} \hlkwb{<-} \hlkwd{cbind}\hlstd{(id, time, sunspots)}

\hlcom{#setup model}
 \hlstd{model} \hlkwb{<-} \hlkwd{ctModel}\hlstd{(}\hlkwc{type}\hlstd{=}\hlstr{'stanct'}\hlstd{,} \hlkwc{n.latent}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{n.manifest}\hlstd{=}\hlnum{1}\hlstd{,}
  \hlkwc{manifestNames}\hlstd{=}\hlstr{'sunspots'}\hlstd{,}
  \hlkwc{latentNames}\hlstd{=}\hlkwd{c}\hlstd{(}\hlstr{'ss_level'}\hlstd{,} \hlstr{'ss_velocity'}\hlstd{),}
   \hlkwc{LAMBDA}\hlstd{=}\hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(} \hlnum{1}\hlstd{,} \hlstr{'ma1'} \hlstd{),} \hlkwc{nrow}\hlstd{=}\hlnum{1}\hlstd{,} \hlkwc{ncol}\hlstd{=}\hlnum{2}\hlstd{),}
   \hlkwc{DRIFT}\hlstd{=}\hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlstr{'a21'}\hlstd{,} \hlnum{1}\hlstd{,} \hlstr{'a22'}\hlstd{),} \hlkwc{nrow}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{ncol}\hlstd{=}\hlnum{2}\hlstd{),}
   \hlkwc{MANIFESTMEANS}\hlstd{=}\hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(}\hlstr{'m1'}\hlstd{),} \hlkwc{nrow}\hlstd{=}\hlnum{1}\hlstd{,} \hlkwc{ncol}\hlstd{=}\hlnum{1}\hlstd{),}
   \hlkwc{CINT}\hlstd{=}\hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{0}\hlstd{),} \hlkwc{nrow}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{ncol}\hlstd{=}\hlnum{1}\hlstd{),}
   \hlkwc{T0VAR}\hlstd{=}\hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{0}\hlstd{,}\hlnum{1}\hlstd{),} \hlkwc{nrow}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{ncol}\hlstd{=}\hlnum{2}\hlstd{),} \hlcom{#Because single subject}
   \hlkwc{DIFFUSION}\hlstd{=}\hlkwd{matrix}\hlstd{(}\hlkwd{c}\hlstd{(}\hlnum{0}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{0}\hlstd{,} \hlstr{"diffusion"}\hlstd{),} \hlkwc{ncol}\hlstd{=}\hlnum{2}\hlstd{,} \hlkwc{nrow}\hlstd{=}\hlnum{2}\hlstd{))}

 \hlstd{model}\hlopt{$}\hlstd{pars}\hlopt{$}\hlstd{indvarying}\hlkwb{<-}\hlnum{FALSE} \hlcom{#Because single subject}
 \hlstd{model}\hlopt{$}\hlstd{pars}\hlopt{$}\hlstd{transform[}\hlnum{14}\hlstd{]}\hlkwb{<-} \hlstr{'(param)*5+44 '} \hlcom{#Because not mean centered}
 \hlstd{model}\hlopt{$}\hlstd{pars}\hlopt{$}\hlstd{transform[}\hlnum{4}\hlstd{]}\hlkwb{<-}\hlstr{'log(exp(-param*1.5)+1)'} \hlcom{#To avoid multi modality }

\hlcom{#fit}
\hlstd{fit} \hlkwb{<-} \hlkwd{ctStanFit}\hlstd{(datalong, model,} \hlkwc{iter}\hlstd{=}\hlnum{300}\hlstd{,} \hlkwc{chains}\hlstd{=}\hlnum{2}\hlstd{)}

\hlcom{#output}
\hlkwd{summary}\hlstd{(fit)}\hlopt{$}\hlstd{popmeans}
\end{alltt}
\begin{verbatim}
                                      mean    sd   2.5%    50%  97.5% n_eff  Rhat
hmean_T0mean_ss_level               24.122 6.148 10.298 24.728 34.545 119.5 1.019
hmean_T0mean_ss_velocity            14.138 7.512 -0.449 13.991 27.612 175.6 1.004
hmean_ma1                            0.659 0.204  0.257  0.653  1.094 112.0 0.997
hmean_a21                           -0.354 0.043 -0.442 -0.353 -0.269 138.9 1.005
hmean_a22                           -0.323 0.081 -0.492 -0.317 -0.183 108.1 1.009
hmean_diffusion                     15.450 2.414 11.463 15.069 20.826  97.2 1.003
hmean_manifestvar_sunspots_sunspots  1.487 1.222  0.127  1.122  4.515 119.1 1.008
hmean_m1                            46.369 2.765 40.928 46.536 51.030 264.9 1.008
\end{verbatim}
\end{kframe}
\end{knitrout}


\subsection{Population standard deviations - understanding the transforms}
Internally, we sample parameters that we will refer to here as the `raw' parameters -- these parameters have no bounds and are drawn from normal distributions. Both population mean (internally: hypermeans) and subject level (internally: indparamsbase) raw parameters are drawn from a normal(0, 1) distribution. Depending on the specific parameter, various transformations may be applied to set appropriate bounds and priors. The population standard deviation (hypersd) for these raw parameters is sampled (by default) from a normal(0, 1) distribution called rawhypersd, which is by default transformed via an exponential function -- ensuring standard deviation parameters are positive and have a prior distribution that could be considered a regularised independence Jeffreys prior. This distribution can be scaled on a per parameter basis by the sdscale multiplier in the model specification, which defaults to 1. The following script shows a didactic sequence of sampling and transformation for a model with a single parameter, the auto effect of the drift matrix, and 50 subjects. Although we sample the priors here, this is merely to reflect the prior and enable understanding and plotting.
\begin{knitrout}\small
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlcom{#population mean and subject level deviations (pre-transformation)}

\hlstd{hypermeans_prior} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlnum{99999}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{)}
\hlstd{hypermeans_post} \hlkwb{<-} \hlopt{-}\hlnum{2} \hlcom{#hypothetical sample}

\hlstd{indparamsbase_prior} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlnum{99999}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{)}
\hlstd{indparamsbase_post} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlnum{50}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{)} \hlcom{#hypothetical sample}

\hlcom{#population standard deviation prior}

\hlstd{rawhypersd_prior} \hlkwb{<-} \hlkwd{rnorm}\hlstd{(}\hlnum{99999}\hlstd{,} \hlnum{0}\hlstd{,} \hlnum{1}\hlstd{)}
\hlstd{hypersd_prior} \hlkwb{<-} \hlkwd{exp}\hlstd{(rawhypersd_prior} \hlopt{*} \hlnum{2} \hlstd{)}

\hlcom{#population standard deviation posterior}

\hlstd{hypersd_post} \hlkwb{<-} \hlnum{.4} \hlcom{#hypothetical}

\hlcom{#square root of population correlation matrix}
\hlstd{hypercorrchol_post} \hlkwb{<-} \hlnum{1} \hlcom{#because only 1 parameter here...}

\hlcom{#population cholesky covariance matrix }
\hlcom{#here based on mean of hypersd_post, for convenience...}
\hlcom{#in reality would have multiple samples.}
\hlstd{hypercovchol} \hlkwb{<-} \hlkwd{diag}\hlstd{(hypercorrchol_post,}\hlnum{1}\hlstd{)} \hlopt{%*%}
  \hlkwd{diag}\hlstd{(hypersd_post,}\hlnum{1}\hlstd{)} \hlopt{%*%} \hlkwd{diag}\hlstd{(hypercorrchol_post,}\hlnum{1}\hlstd{)}

\hlcom{#subject level parameters}
\hlcom{#first compute pre transformation parameters}
\hlcom{#then transform appropriately (here according to drift auto effect)}
\hlstd{indparams} \hlkwb{<-} \hlstd{hypercovchol} \hlopt{%*%} \hlstd{indparamsbase_post} \hlopt{+} \hlstd{hypermeans_post}
\hlstd{indparams} \hlkwb{<-} \hlopt{-}\hlkwd{log}\hlstd{(}\hlkwd{exp}\hlstd{(}\hlopt{-}\hlnum{1.5} \hlopt{*} \hlstd{indparams)} \hlopt{+} \hlnum{1}\hlstd{)}

\hlcom{#post transformation population standard deviation}
\hlstd{hsd_ourparameter} \hlkwb{<-} \hlkwd{abs}\hlstd{(} \hlcom{#via delta approximation}
  \hlstd{(}\hlopt{-}\hlkwd{log}\hlstd{(}\hlkwd{exp}\hlstd{(}\hlopt{-}\hlnum{1.5} \hlopt{*} \hlstd{(hypermeans_post} \hlopt{+} \hlstd{hypersd_post))} \hlopt{+} \hlnum{1}\hlstd{)} \hlopt{-}
   \hlopt{-}\hlkwd{log}\hlstd{(}\hlkwd{exp}\hlstd{(}\hlopt{-}\hlnum{1.5} \hlopt{*} \hlstd{(hypermeans_post} \hlopt{-} \hlstd{hypersd_post))} \hlopt{+} \hlnum{1}\hlstd{) )} \hlopt{/} \hlnum{2}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}



\section{The model}
For a comprehensive description of the statistical model, see \url{http://www.researchgate.net/publication/310747801_Hierarchical_Bayesian_Continuous_Time_Dynamic_Modeling}.

\bibliography{hierarchicalreferences}

\end{document}





